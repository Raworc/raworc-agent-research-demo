from dotenv import load_dotenv
from pydantic import BaseModel
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from langchain.agents import create_tool_calling_agent, AgentExecutor
from tools import get_research_tools
import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Dict, Any

# Enhanced imports
from reportlab.lib.pagesizes import letter, A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeRemainingColumn
from rich.table import Table
from rich.text import Text
from rich.prompt import Prompt, Confirm
from rich.tree import Tree
from rich.markdown import Markdown
from tqdm import tqdm
import time

# Import our new modules
from config import get_config, update_config, ensure_directories
from cache import get_cached_result, cache_result, get_cache_stats, cleanup_expired_cache
from templates import get_available_templates, get_template_queries, get_template_info

load_dotenv()

# Initialize console for rich formatting
console = Console()

class ResearchResponse(BaseModel):
    topic: str
    summary: str
    key_points: list[str]
    sources: list[str]
    tools_used: list[str]

# Initialize configuration and ensure directories exist
config = get_config()
ensure_directories()

# Initialize LLM with config settings
llm_kwargs = {
    "model": config.model_name,
    "temperature": config.temperature
}

# Only add max_tokens if it's not None
if config.max_tokens is not None:
    llm_kwargs["max_tokens"] = config.max_tokens

llm = ChatAnthropic(**llm_kwargs)
parser = PydanticOutputParser(pydantic_object=ResearchResponse)

prompt = ChatPromptTemplate.from_messages([
    ("system", 
    """You are a research assistant that will help the user with their research paper.
     Use the available tools to research the user's query thoroughly.
     
     IMPORTANT: Your final response must be ONLY valid JSON in the exact format specified below.
     Do not include any explanatory text before or after the JSON.
     Do not include duplicate keys in the JSON.
     Make sure all JSON is properly closed with matching braces and brackets.
     
     {format_instructions}"""),

    ("placeholder","{chat_history}"),
    ("human", "{query}"),
    ("placeholder", "{agent_scratchpad}"),
]
).partial(format_instructions=parser.get_format_instructions())

tools = get_research_tools()

agent = create_tool_calling_agent(
    llm,
    prompt = prompt, 
    tools=tools
)

def print_research_results(structured_response: ResearchResponse):
    """Print research results with enhanced rich formatting"""
    if config.use_rich_formatting:
        # Create a beautiful panel for the results
        console.print("\n")
        console.print(Panel.fit(
            f"[bold blue]RESEARCH RESULTS[/bold blue]\n"
            f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            f"Topic: [bold]{structured_response.topic}[/bold]",
            border_style="blue"
        ))
        
        # Executive Summary
        console.print("\n📊 [bold cyan]EXECUTIVE SUMMARY[/bold cyan]")
        console.print(Panel(
            structured_response.summary,
            border_style="cyan",
            padding=(1, 2)
        ))
        
        # Key Insights
        console.print(f"\n💡 [bold yellow]KEY INSIGHTS[/bold yellow] [dim]({len(structured_response.key_points)} points)[/dim]")
        
        # Create a table for key insights
        table = Table(show_header=False, box=None, padding=(0, 1))
        table.add_column("No.", style="bold blue", width=4)
        table.add_column("Insight", style="white")
        
        for i, point in enumerate(structured_response.key_points, 1):
            table.add_row(f"{i}.", point)
        
        console.print(table)
        
        # Sources section
        if structured_response.sources:
            console.print(f"\n📚 [bold green]SOURCES[/bold green] [dim]({len(structured_response.sources)} references)[/dim]")
            
            source_table = Table(show_header=False, box=None, padding=(0, 1))
            source_table.add_column("No.", style="bold blue", width=4)
            source_table.add_column("Source", style="white")
            
            for i, source in enumerate(structured_response.sources, 1):
                source_table.add_row(f"{i}.", source)
            
            console.print(source_table)
        
        # Footer
        console.print("\n")
        console.print(Panel.fit(
            "[bold green]✅ Research Complete[/bold green]\n[dim]Generated by Raworc Agent[/dim]",
            border_style="green"
        ))
    else:
        # Fallback to simple formatting
        print("\nRESEARCH RESULTS")
        print(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"Topic: {structured_response.topic}")
        
        print("\nEXECUTIVE SUMMARY")
        print("-" * 50)
        print(f"{structured_response.summary}")
        
        print(f"\nKEY INSIGHTS ({len(structured_response.key_points)} points)")
        print("-" * 50)
        for i, point in enumerate(structured_response.key_points, 1):
            print(f"{i:2d}. {point}")
        
        if structured_response.sources:
            print(f"\nSOURCES ({len(structured_response.sources)} references)")
            print("-" * 50)
            for i, source in enumerate(structured_response.sources, 1):
                print(f"{i:2d}. {source}")
        
        print("\nResearch Complete.")
        print("Generated by Raworc Agent")

def save_results_to_json(structured_response: ResearchResponse, filename: str = None):
    """Save research results to a JSON file"""
    if filename is None:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"research_results_{timestamp}.json"
    
    # Create a modified version without tools_used and with attribution
    response_dict = structured_response.dict()
    response_dict.pop('tools_used', None)  # Remove tools_used if it exists
    response_dict['generated_by'] = 'Raworc Agent'
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(response_dict, f, indent=2, ensure_ascii=False)
    
    return filename

def save_results_to_text(structured_response: ResearchResponse, filename: str = None):
    """Save research results to a text file"""
    if filename is None:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"research_results_{timestamp}.txt"
    
    with open(filename, 'w', encoding='utf-8') as f:
        f.write("RESEARCH RESULTS\n")
        f.write("=" * 50 + "\n\n")
        f.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Topic: {structured_response.topic}\n\n")
        
        f.write("EXECUTIVE SUMMARY\n")
        f.write("-" * 30 + "\n")
        f.write(f"{structured_response.summary}\n\n")
        
        f.write(f"KEY INSIGHTS ({len(structured_response.key_points)} points)\n")
        f.write("-" * 30 + "\n")
        for i, point in enumerate(structured_response.key_points, 1):
            f.write(f"{i:2d}. {point}\n")
        f.write("\n")
        
        if structured_response.sources:
            f.write(f"SOURCES ({len(structured_response.sources)} references)\n")
            f.write("-" * 30 + "\n")
            for i, source in enumerate(structured_response.sources, 1):
                f.write(f"{i:2d}. {source}\n")
            f.write("\n")
        
        f.write("Research Complete.\n")
        f.write("\n" + "="*50 + "\n")
        f.write("Generated by Raworc Agent\n")
    
    return filename

def save_results_to_pdf(structured_response: ResearchResponse, filename: str = None):
    """Save research results to a PDF file"""
    if filename is None:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"research_results_{timestamp}.pdf"
    
    # Create PDF document
    doc = SimpleDocTemplate(filename, pagesize=A4)
    styles = getSampleStyleSheet()
    
    # Custom styles
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=18,
        spaceAfter=20,
        textColor='black'
    )
    
    heading_style = ParagraphStyle(
        'CustomHeading',
        parent=styles['Heading2'],
        fontSize=14,
        spaceAfter=12,
        textColor='black'
    )
    
    normal_style = styles['Normal']
    
    # Build content
    content = []
    
    # Title
    content.append(Paragraph("RESEARCH RESULTS", title_style))
    content.append(Spacer(1, 12))
    
    # Metadata
    content.append(Paragraph(f"<b>Generated:</b> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", normal_style))
    content.append(Paragraph(f"<b>Topic:</b> {structured_response.topic}", normal_style))
    content.append(Spacer(1, 20))
    
    # Executive Summary
    content.append(Paragraph("EXECUTIVE SUMMARY", heading_style))
    content.append(Paragraph(structured_response.summary, normal_style))
    content.append(Spacer(1, 20))
    
    # Key Insights
    content.append(Paragraph(f"KEY INSIGHTS ({len(structured_response.key_points)} points)", heading_style))
    for i, point in enumerate(structured_response.key_points, 1):
        content.append(Paragraph(f"{i}. {point}", normal_style))
    content.append(Spacer(1, 20))
    
    # Sources
    if structured_response.sources:
        content.append(Paragraph(f"SOURCES ({len(structured_response.sources)} references)", heading_style))
        for i, source in enumerate(structured_response.sources, 1):
            content.append(Paragraph(f"{i}. {source}", normal_style))
        content.append(Spacer(1, 20))
    
    # Footer
    content.append(Spacer(1, 30))
    content.append(Paragraph("Research Complete.", normal_style))
    content.append(Spacer(1, 20))
    content.append(Paragraph("Generated by Raworc Agent", normal_style))
    
    # Build PDF
    doc.build(content)
    
    return filename

def offer_download_options(structured_response: ResearchResponse):
    """Offer download options to the user with enhanced UI"""
    if config.auto_save:
        # Auto-save in the default format
        if config.default_format == "json":
            filename = save_results_to_json(structured_response)
        elif config.default_format == "txt":
            filename = save_results_to_text(structured_response)
        elif config.default_format == "pdf":
            filename = save_results_to_pdf(structured_response)
        elif config.default_format == "all":
            save_all_formats(structured_response)
            return
        
        if config.use_rich_formatting:
            console.print(f"\n💾 [green]Auto-saved as: {filename}[/green]")
        else:
            print(f"\nAuto-saved as: {filename}")
        return
    
    if config.use_rich_formatting:
        console.print("\n💾 [bold cyan]Download Options[/bold cyan]")
        table = Table(show_header=False, box=None)
        table.add_column("Option", style="bold blue", width=8)
        table.add_column("Description", style="white")
        
        table.add_row("1", "JSON file (.json)")
        table.add_row("2", "Text file (.txt)")
        table.add_row("3", "PDF file (.pdf)")
        table.add_row("4", "All formats")
        table.add_row("5", "Skip download")
        
        console.print(table)
        
        choice = Prompt.ask(
            "\n[bold]Select download option[/bold]",
            choices=["1", "2", "3", "4", "5"],
            default="5"
        )
    else:
        print("\nDownload Options:")
        print("1. JSON file")
        print("2. Text file (.txt)")
        print("3. PDF file")
        print("4. All formats")
        print("5. Skip download")
        choice = input("\nSelect download option (1-5): ").strip()
    
    output_dir = Path(config.output_directory)
    
    if choice == "1":
        filename = save_results_to_json(structured_response)
        console.print(f"✅ [green]JSON file saved: {filename}[/green]") if config.use_rich_formatting else print(f"JSON file saved: {filename}")
    elif choice == "2":
        filename = save_results_to_text(structured_response)
        console.print(f"✅ [green]Text file saved: {filename}[/green]") if config.use_rich_formatting else print(f"Text file saved: {filename}")
    elif choice == "3":
        try:
            filename = save_results_to_pdf(structured_response)
            console.print(f"✅ [green]PDF file saved: {filename}[/green]") if config.use_rich_formatting else print(f"PDF file saved: {filename}")
        except Exception as e:
            console.print(f"❌ [red]Error creating PDF: {e}[/red]") if config.use_rich_formatting else print(f"Error creating PDF: {e}")
            console.print("[yellow]Falling back to text file...[/yellow]") if config.use_rich_formatting else print("Falling back to text file...")
            filename = save_results_to_text(structured_response)
            console.print(f"✅ [green]Text file saved: {filename}[/green]") if config.use_rich_formatting else print(f"Text file saved: {filename}")
    elif choice == "4":
        save_all_formats(structured_response)
    elif choice == "5":
        console.print("📤 [yellow]Download skipped[/yellow]") if config.use_rich_formatting else print("Download skipped.")

def save_all_formats(structured_response: ResearchResponse):
    """Save research results in all available formats"""
    files_saved = []
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console,
        transient=True
    ) as progress:
        task = progress.add_task("Saving files...", total=3)
        
        # Save JSON
        progress.update(task, description="Saving JSON file...")
        json_file = save_results_to_json(structured_response)
        files_saved.append(json_file)
        progress.advance(task)
        
        # Save Text
        progress.update(task, description="Saving text file...")
        text_file = save_results_to_text(structured_response)
        files_saved.append(text_file)
        progress.advance(task)
        
        # Save PDF
        progress.update(task, description="Saving PDF file...")
        try:
            pdf_file = save_results_to_pdf(structured_response)
            files_saved.append(pdf_file)
        except Exception as e:
            console.print(f"❌ [red]Error creating PDF: {e}[/red]") if config.use_rich_formatting else print(f"Error creating PDF: {e}")
        progress.advance(task)
    
    if config.use_rich_formatting:
        console.print(f"\n✅ [green]Files saved:[/green]")
        for file in files_saved:
            console.print(f"   📄 {file}")
    else:
        print(f"\nFiles saved: {', '.join(files_saved)}")

def conduct_research(query: str):
    """Conduct research on a given query with caching and enhanced progress tracking"""
    
    # Check cache first
    cached_result = get_cached_result(query, "research")
    if cached_result and not config.verbose_mode:
        if config.use_rich_formatting:
            console.print("📄 [yellow]Using cached result...[/yellow]")
        else:
            print("Using cached result...")
        
        try:
            # Reconstruct ResearchResponse from cached data
            structured_response = ResearchResponse(**cached_result)
            print_research_results(structured_response)
            offer_download_options(structured_response)
            return structured_response
        except Exception as e:
            if config.use_rich_formatting:
                console.print(f"⚠️ [yellow]Cache corrupted, performing fresh research...[/yellow]")
            else:
                print("Cache corrupted, performing fresh research...")
    
    # Start fresh research
    if config.use_rich_formatting:
        console.print("\n🔍 [bold blue]Starting Research Agent[/bold blue]")
        console.print(f"📝 [cyan]Query: {query}[/cyan]")
        console.print("─" * 80)
    else:
        print("Starting research agent...")
        print(f"Processing query: '{query}'")
        print("-" * 80)

    agent_executor = AgentExecutor(
        agent=agent, 
        tools=tools, 
        verbose=config.verbose_mode,
        max_iterations=15,
        early_stopping_method="generate"
    )
    
    # Show progress with spinner
    if config.show_progress_bars and config.use_rich_formatting:
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console,
            transient=True
        ) as progress:
            task = progress.add_task("🤖 AI Agent is researching...", total=None)
            
            try:
                raw_response = agent_executor.invoke({"query": query})
            except Exception as e:
                console.print(f"❌ [red]Research failed: {e}[/red]")
                return None
    else:
        try:
            raw_response = agent_executor.invoke({"query": query})
        except Exception as e:
            print(f"Research failed: {e}")
            return None

    # Debug output for verbose mode
    if config.verbose_mode:
        console.print(f"\n🔧 [dim]DEBUG - Raw response type: {type(raw_response)}[/dim]") if config.use_rich_formatting else print(f"\nDEBUG - Raw response type: {type(raw_response)}")
        console.print(f"🔧 [dim]DEBUG - Raw response keys: {raw_response.keys() if isinstance(raw_response, dict) else 'Not a dict'}[/dim]") if config.use_rich_formatting else print(f"DEBUG - Raw response keys: {raw_response.keys() if isinstance(raw_response, dict) else 'Not a dict'}")
    
    # AgentExecutor returns the final output in the 'output' key
    output_text = raw_response.get("output", "")
    
    # Handle case where output might be a list
    if isinstance(output_text, list) and len(output_text) > 0:
        if isinstance(output_text[0], dict) and 'text' in output_text[0]:
            output_text = output_text[0]['text']
        else:
            output_text = str(output_text[0])
    
    if config.verbose_mode:
        console.print(f"🔧 [dim]DEBUG - Output text preview: {str(output_text)[:200]}...[/dim]") if config.use_rich_formatting else print(f"DEBUG - Output text preview: {str(output_text)[:200]}...")

    try:
        structured_response = parser.parse(output_text)
        
        # Cache the successful result
        cache_result(query, structured_response.dict(), "research")
        
        # Print beautifully formatted results
        print_research_results(structured_response)
        
        # Offer download options
        offer_download_options(structured_response)
        
        return structured_response
        
    except Exception as e:
        if config.use_rich_formatting:
            console.print(f"\n❌ [red]ERROR during parsing: {e}[/red]")
        else:
            print(f"\nERROR OCCURRED during parsing: {e}")
        
        # Try to create a fallback structured response
        try:
            if config.use_rich_formatting:
                console.print("🔄 [yellow]Attempting fallback response creation...[/yellow]")
            else:
                print("Attempting fallback response creation...")
            
            fallback_response = create_fallback_response(output_text, query)
            
            if fallback_response:
                # Cache the fallback result too
                cache_result(query, fallback_response.dict(), "research")
                
                if config.use_rich_formatting:
                    console.print("✅ [green]Fallback response created successfully![/green]")
                else:
                    print("Fallback response created successfully!")
                
                print_research_results(fallback_response)
                offer_download_options(fallback_response)
                return fallback_response
            
        except Exception as fallback_error:
            if config.use_rich_formatting:
                console.print(f"❌ [red]Fallback also failed: {fallback_error}[/red]")
            else:
                print(f"Fallback also failed: {fallback_error}")
        
        # Show raw output for debugging
        if config.verbose_mode:
            if config.use_rich_formatting:
                console.print("\n📄 [yellow]Raw output received:[/yellow]")
                console.print(Panel(str(output_text), title="Raw Output", border_style="yellow"))
            else:
                print("\nRaw output received:")
                print("-" * 30)
                print(output_text)
                print("-" * 30)
        
        # Offer to save raw output
        if config.use_rich_formatting:
            save_raw = Confirm.ask("Would you like to save the raw output as text?")
        else:
            save_raw = input("Would you like to save the raw output as text? (y/n): ").strip().lower() in ['y', 'yes']
        
        if save_raw:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = Path(config.output_directory) / f"raw_output_{timestamp}.txt"
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(f"Query: {query}\n")
                f.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("="*50 + "\n\n")
                f.write(str(output_text))
            
            if config.use_rich_formatting:
                console.print(f"📄 [green]Raw output saved to: {filename}[/green]")
            else:
                print(f"Raw output saved to: {filename}")
        
        return None

def create_fallback_response(raw_text: str, query: str) -> ResearchResponse:
    """Create a fallback structured response from raw text"""
    
    # Clean the raw text
    if isinstance(raw_text, str):
        text = raw_text.strip()
    else:
        text = str(raw_text).strip()
    
    # Basic fallback structure
    fallback = ResearchResponse(
        topic=query[:100] + "..." if len(query) > 100 else query,
        summary=text[:500] + "..." if len(text) > 500 else text,
        key_points=[
            "Raw research data retrieved from Wikipedia",
            "Manual processing may be required for detailed analysis",
            "Content extracted from AI research agent"
        ],
        sources=["Wikipedia API"],
        tools_used=[]
    )
    
    return fallback

def get_user_query():
    """Get research query from user with enhanced input handling"""
    if config.use_rich_formatting:
        console.print("\n📝 [bold cyan]Research Query Input[/bold cyan]")
        console.print(Panel(
            "[yellow]Tips:[/yellow]\n"
            "• Be specific about what you want to research\n"
            "• You can ask multiple questions in one query\n"
            "• Examples: 'How does blockchain work?', 'Compare Python vs Java'",
            title="Input Guidelines",
            border_style="cyan"
        ))
    else:
        print("\nResearch Query Input")
        print("-" * 50)
        print("Tips:")
        print("   • Be specific about what you want to research")
        print("   • You can ask multiple questions in one query")
        print("   • Examples: 'How does blockchain work?', 'Compare Python vs Java'")
    
    while True:
        if config.use_rich_formatting:
            query = Prompt.ask("\n[bold]Enter your research question[/bold]").strip()
        else:
            query = input("\nEnter your research question: ").strip()
        
        if not query:
            if config.use_rich_formatting:
                console.print("❌ [red]Error: Query cannot be empty. Please enter a valid research question.[/red]")
            else:
                print("Error: Query cannot be empty. Please enter a valid research question.")
            continue
            
        if len(query) < 10:
            if config.use_rich_formatting:
                console.print("❌ [red]Error: Query too short. Please provide more details (at least 10 characters).[/red]")
            else:
                print("Error: Query too short. Please provide more details (at least 10 characters).")
            continue
            
        # Confirm the query
        if config.use_rich_formatting:
            console.print(f"\n📋 [bold]Your query:[/bold] [cyan]{query}[/cyan]")
            confirm = Confirm.ask("Proceed with this query?", default=True)
        else:
            print(f"\nYour query: '{query}'")
            confirm = input("Proceed with this query? (y/n): ").strip().lower() in ['y', 'yes', '']
        
        if confirm:
            return query
        else:
            if config.use_rich_formatting:
                console.print("🔄 [yellow]Let's try again...[/yellow]")
            else:
                print("Let's try again...")
            continue

def show_template_options():
    """Show available research templates and let user choose"""
    templates = get_available_templates()
    
    if config.use_rich_formatting:
        console.print("\n🎯 [bold cyan]Available Research Templates[/bold cyan]")
        
        table = Table(show_header=True, header_style="bold blue")
        table.add_column("No.", style="bold blue", width=4)
        table.add_column("Template", style="bold cyan")
        table.add_column("Description", style="white")
        
        for i, (name, description) in enumerate(templates, 1):
            table.add_row(str(i), name.title(), description)
        
        console.print(table)
        
        choices = [str(i) for i in range(1, len(templates) + 1)] + ['0']
        choice = Prompt.ask(
            "\n[bold]Select a template (0 for custom query)[/bold]",
            choices=choices,
            default="0"
        )
    else:
        print("\nAvailable Research Templates:")
        print("-" * 50)
        for i, (name, description) in enumerate(templates, 1):
            print(f"{i}. {name.title()}: {description}")
        print("0. Custom query (no template)")
        
        choice = input("\nSelect a template (0-{}): ".format(len(templates))).strip()
    
    if choice == "0":
        return None, None
    
    try:
        template_index = int(choice) - 1
        if 0 <= template_index < len(templates):
            template_name = templates[template_index][0]
            
            # Get the topic for the template
            if config.use_rich_formatting:
                topic = Prompt.ask(f"\n[bold]Enter the topic for {template_name.title()} research[/bold]")
            else:
                topic = input(f"\nEnter the topic for {template_name.title()} research: ").strip()
            
            return template_name, topic
        else:
            if config.use_rich_formatting:
                console.print("❌ [red]Invalid choice. Using custom query.[/red]")
            else:
                print("Invalid choice. Using custom query.")
            return None, None
    except ValueError:
        if config.use_rich_formatting:
            console.print("❌ [red]Invalid input. Using custom query.[/red]")
        else:
            print("Invalid input. Using custom query.")
        return None, None

def show_settings_menu():
    """Show settings configuration menu"""
    if config.use_rich_formatting:
        console.print("\n⚙️ [bold cyan]Settings Configuration[/bold cyan]")
        
        # Current settings table
        table = Table(title="Current Settings", show_header=True, header_style="bold blue")
        table.add_column("Setting", style="bold cyan")
        table.add_column("Value", style="white")
        
        table.add_row("Model", config.model_name)
        table.add_row("Temperature", str(config.temperature))
        table.add_row("Rich Formatting", "✅ Enabled" if config.use_rich_formatting else "❌ Disabled")
        table.add_row("Progress Bars", "✅ Enabled" if config.show_progress_bars else "❌ Disabled")
        table.add_row("Verbose Mode", "✅ Enabled" if config.verbose_mode else "❌ Disabled")
        table.add_row("Caching", "✅ Enabled" if config.enable_caching else "❌ Disabled")
        table.add_row("Auto Save", "✅ Enabled" if config.auto_save else "❌ Disabled")
        table.add_row("Default Format", config.default_format)
        table.add_row("Output Directory", config.output_directory)
        
        console.print(table)
        
        # Settings options
        console.print("\n📋 [bold]Settings Options[/bold]")
        options_table = Table(show_header=False, box=None)
        options_table.add_column("Option", style="bold blue", width=4)
        options_table.add_column("Description", style="white")
        
        options_table.add_row("1", "Toggle verbose mode")
        options_table.add_row("2", "Toggle caching")
        options_table.add_row("3", "Toggle auto-save")
        options_table.add_row("4", "Change default format")
        options_table.add_row("5", "View cache statistics")
        options_table.add_row("6", "Clear cache")
        options_table.add_row("7", "Reset to defaults")
        options_table.add_row("0", "Back to main menu")
        
        console.print(options_table)
        
        choice = Prompt.ask(
            "\n[bold]Select an option[/bold]",
            choices=["0", "1", "2", "3", "4", "5", "6", "7"],
            default="0"
        )
    else:
        print("\nSettings Configuration")
        print("-" * 50)
        print(f"Current Settings:")
        print(f"  Model: {config.model_name}")
        print(f"  Temperature: {config.temperature}")
        print(f"  Verbose Mode: {'Enabled' if config.verbose_mode else 'Disabled'}")
        print(f"  Caching: {'Enabled' if config.enable_caching else 'Disabled'}")
        print(f"  Auto Save: {'Enabled' if config.auto_save else 'Disabled'}")
        print(f"  Default Format: {config.default_format}")
        print(f"  Output Directory: {config.output_directory}")
        
        print("\nOptions:")
        print("1. Toggle verbose mode")
        print("2. Toggle caching")
        print("3. Toggle auto-save")
        print("4. Change default format")
        print("5. View cache statistics")
        print("6. Clear cache")
        print("7. Reset to defaults")
        print("0. Back to main menu")
        
        choice = input("\nSelect an option (0-7): ").strip()
    
    if choice == "1":
        update_config(verbose_mode=not config.verbose_mode)
        status = "enabled" if config.verbose_mode else "disabled"
        if config.use_rich_formatting:
            console.print(f"✅ [green]Verbose mode {status}[/green]")
        else:
            print(f"Verbose mode {status}")
    
    elif choice == "2":
        update_config(enable_caching=not config.enable_caching)
        status = "enabled" if config.enable_caching else "disabled"
        if config.use_rich_formatting:
            console.print(f"✅ [green]Caching {status}[/green]")
        else:
            print(f"Caching {status}")
    
    elif choice == "3":
        update_config(auto_save=not config.auto_save)
        status = "enabled" if config.auto_save else "disabled"
        if config.use_rich_formatting:
            console.print(f"✅ [green]Auto-save {status}[/green]")
        else:
            print(f"Auto-save {status}")
    
    elif choice == "4":
        formats = ["json", "txt", "pdf", "all"]
        if config.use_rich_formatting:
            new_format = Prompt.ask(
                "Select default format",
                choices=formats,
                default=config.default_format
            )
        else:
            print(f"Available formats: {', '.join(formats)}")
            new_format = input(f"Enter new default format ({config.default_format}): ").strip() or config.default_format
        
        if new_format in formats:
            update_config(default_format=new_format)
            if config.use_rich_formatting:
                console.print(f"✅ [green]Default format changed to: {new_format}[/green]")
            else:
                print(f"Default format changed to: {new_format}")
        else:
            if config.use_rich_formatting:
                console.print("❌ [red]Invalid format[/red]")
            else:
                print("Invalid format")
    
    elif choice == "5":
        stats = get_cache_stats()
        if config.use_rich_formatting:
            console.print(f"\n📊 [bold cyan]Cache Statistics[/bold cyan]")
            stats_table = Table(show_header=False, box=None)
            stats_table.add_column("Metric", style="bold blue")
            stats_table.add_column("Value", style="white")
            
            stats_table.add_row("Total Files", str(stats['total_files']))
            stats_table.add_row("Total Size", f"{stats['total_size_mb']} MB")
            stats_table.add_row("Valid Files", str(stats['valid_files']))
            stats_table.add_row("Expired Files", str(stats['expired_files']))
            
            console.print(stats_table)
        else:
            print(f"\nCache Statistics:")
            print(f"  Total Files: {stats['total_files']}")
            print(f"  Total Size: {stats['total_size_mb']} MB")
            print(f"  Valid Files: {stats['valid_files']}")
            print(f"  Expired Files: {stats['expired_files']}")
    
    elif choice == "6":
        if config.use_rich_formatting:
            if Confirm.ask("Are you sure you want to clear the cache?"):
                deleted_count = cleanup_expired_cache()
                console.print(f"✅ [green]Cleared {deleted_count} expired cache files[/green]")
        else:
            confirm = input("Are you sure you want to clear the cache? (y/n): ").strip().lower()
            if confirm in ['y', 'yes']:
                deleted_count = cleanup_expired_cache()
                print(f"Cleared {deleted_count} expired cache files")
    
    elif choice == "7":
        if config.use_rich_formatting:
            if Confirm.ask("Are you sure you want to reset all settings to defaults?"):
                config_manager.reset_to_defaults()
                console.print("✅ [green]Settings reset to defaults[/green]")
        else:
            confirm = input("Are you sure you want to reset all settings to defaults? (y/n): ").strip().lower()
            if confirm in ['y', 'yes']:
                config_manager.reset_to_defaults()
                print("Settings reset to defaults")

def display_menu():
    """Display the enhanced main menu"""
    if config.use_rich_formatting:
        console.print(Panel.fit(
            "[bold blue]🔬 Advanced Research Agent[/bold blue]\n"
            "[dim]Powered by Raworc AI[/dim]",
            border_style="blue"
        ))
        
        table = Table(show_header=False, box=None, padding=(0, 2))
        table.add_column("Option", style="bold blue", width=4)
        table.add_column("Description", style="white")
        
        table.add_row("1", "🔍 Custom Research Query")
        table.add_row("2", "🎯 Template-Based Research") 
        table.add_row("3", "🎮 Demo Query (Generative AI vs LLM)")
        table.add_row("4", "⚙️ Settings & Configuration")
        table.add_row("5", "📊 Cache Statistics")
        table.add_row("6", "❓ Help & Information")
        table.add_row("0", "🚪 Exit")
        
        console.print(table)
    else:
        print("\nAdvanced Research Agent - Main Menu")
        print("Powered by Raworc AI")
        print("-" * 50)
        print("1. Custom Research Query")
        print("2. Template-Based Research")
        print("3. Demo Query (Generative AI vs LLM)")
        print("4. Settings & Configuration") 
        print("5. Cache Statistics")
        print("6. Help & Information")
        print("0. Exit")

def show_help():
    """Show help and information about the research agent"""
    if config.use_rich_formatting:
        console.print("\n❓ [bold cyan]Help & Information[/bold cyan]")
        
        help_content = """
[bold yellow]🔍 Research Capabilities:[/bold yellow]
• Wikipedia search for general knowledge
• Web search for current information and trends
• News search for latest developments
• Academic papers search (arXiv)
• Web content extraction from specific URLs

[bold yellow]🎯 Research Templates:[/bold yellow]
• Technology Research - for tech topics and innovations
• Business Analysis - for market and company research
• Academic Research - for scholarly topics
• Health & Medicine - for medical and wellness topics
• Historical Research - for events and historical figures
• Comparative Analysis - for comparing options

[bold yellow]💾 Export Options:[/bold yellow]
• JSON format for structured data
• Text format for readable reports
• PDF format for professional documents
• All formats at once

[bold yellow]⚙️ Configuration Features:[/bold yellow]
• Caching system for faster repeated queries
• Auto-save options
• Verbose mode for debugging
• Customizable output formats
• Rich formatting controls

[bold yellow]🎮 Usage Tips:[/bold yellow]
• Be specific in your research questions
• Use templates for structured research
• Enable caching for better performance
• Check settings for customization options
        """
        
        console.print(Panel(help_content, title="Research Agent Guide", border_style="cyan"))
    else:
        print("\nHelp & Information")
        print("-" * 50)
        print("Research Capabilities:")
        print("• Wikipedia search for general knowledge")
        print("• Web search for current information and trends")
        print("• News search for latest developments")
        print("• Academic papers search (arXiv)")
        print("• Web content extraction from specific URLs")
        print("\nResearch Templates:")
        print("• Technology Research")
        print("• Business Analysis")
        print("• Academic Research")
        print("• Health & Medicine")
        print("• Historical Research")
        print("• Comparative Analysis")
        print("\nExport Options:")
        print("• JSON, Text, PDF formats")
        print("• Auto-save capabilities")
        print("\nConfiguration Features:")
        print("• Caching system")
        print("• Verbose mode")
        print("• Customizable settings")

def main():
    """Enhanced main function to run the research agent"""
    if config.use_rich_formatting:
        console.print(Panel.fit(
            "[bold green]🚀 Welcome to the Advanced AI Research Agent![/bold green]\n"
            "[cyan]Enhanced with multiple search tools, caching, and smart templates[/cyan]\n"
            "[dim]Powered by Raworc AI • Version 2.0[/dim]",
            border_style="green"
        ))
    else:
        print("Welcome to the Advanced AI Research Agent!")
        print("Enhanced with multiple search tools, caching, and smart templates")
        print("Powered by Raworc AI")
    
    # Cleanup expired cache on startup
    if config.enable_caching:
        cleanup_expired_cache()
    
    while True:
        display_menu()
        
        try:
            if config.use_rich_formatting:
                choice = Prompt.ask(
                    "\n[bold]Select an option[/bold]",
                    choices=["0", "1", "2", "3", "4", "5", "6"],
                    default="1"
                )
            else:
                choice = input("\nSelect an option (0-6): ").strip()
            
            if choice == "1":
                query = get_user_query()
                conduct_research(query)
                
            elif choice == "2":
                template_name, topic = show_template_options()
                
                if template_name and topic:
                    # Generate queries using the template
                    template_queries = get_template_queries(template_name, topic)
                    
                    if config.use_rich_formatting:
                        console.print(f"\n🎯 [bold cyan]Using {template_name.title()} template for: {topic}[/bold cyan]")
                        
                        # Show generated queries
                        console.print("\n📋 [bold]Generated Research Questions:[/bold]")
                        for i, q in enumerate(template_queries, 1):
                            console.print(f"  {i}. {q}")
                        
                        # Combine queries for comprehensive research
                        combined_query = f"Research about {topic}: " + " ".join(template_queries)
                    else:
                        print(f"\nUsing {template_name.title()} template for: {topic}")
                        print("Generated Research Questions:")
                        for i, q in enumerate(template_queries, 1):
                            print(f"  {i}. {q}")
                        combined_query = f"Research about {topic}: " + " ".join(template_queries)
                    
                    conduct_research(combined_query)
                else:
                    # Fall back to custom query
                    query = get_user_query()
                    conduct_research(query)
                
            elif choice == "3":
                if config.use_rich_formatting:
                    console.print("\n🎮 [bold cyan]Running demo query...[/bold cyan]")
                else:
                    print("\nRunning demo query...")
                default_query = "What is generative AI and how does it work? What is the difference between generative AI and large language models? What are the current applications and future prospects?"
                conduct_research(default_query)
                
            elif choice == "4":
                show_settings_menu()
                
            elif choice == "5":
                stats = get_cache_stats()
                if config.use_rich_formatting:
                    console.print(f"\n📊 [bold cyan]Cache Statistics[/bold cyan]")
                    
                    table = Table(show_header=True, header_style="bold blue")
                    table.add_column("Metric", style="bold cyan")
                    table.add_column("Value", style="white")
                    
                    table.add_row("Total Cache Files", str(stats['total_files']))
                    table.add_row("Total Size", f"{stats['total_size_mb']} MB")
                    table.add_row("Valid Files", str(stats['valid_files']))
                    table.add_row("Expired Files", str(stats['expired_files']))
                    table.add_row("Cache Status", "✅ Enabled" if config.enable_caching else "❌ Disabled")
                    
                    console.print(table)
                else:
                    print(f"\nCache Statistics:")
                    print(f"  Total Cache Files: {stats['total_files']}")
                    print(f"  Total Size: {stats['total_size_mb']} MB")
                    print(f"  Valid Files: {stats['valid_files']}")
                    print(f"  Expired Files: {stats['expired_files']}")
                    print(f"  Cache Status: {'Enabled' if config.enable_caching else 'Disabled'}")
                
            elif choice == "6":
                show_help()
                
            elif choice == "0":
                if config.use_rich_formatting:
                    console.print("\n👋 [bold green]Thank you for using the Advanced Research Agent![/bold green]")
                    console.print("[cyan]Happy researching![/cyan] 🔬✨")
                else:
                    print("\nThank you for using the Advanced Research Agent!")
                    print("Happy researching!")
                break
                
            else:
                if config.use_rich_formatting:
                    console.print("❌ [red]Invalid choice. Please select 0-6.[/red]")
                else:
                    print("Invalid choice. Please select 0-6.")
                continue
                
        except KeyboardInterrupt:
            if config.use_rich_formatting:
                console.print("\n\n⚠️ [yellow]Research interrupted by user.[/yellow]")
                console.print("👋 [green]Thank you for using the Advanced Research Agent![/green]")
            else:
                print("\n\nResearch interrupted by user.")
                print("Thank you for using the Advanced Research Agent!")
            break
        except Exception as e:
            if config.use_rich_formatting:
                console.print(f"\n❌ [red]Unexpected error: {e}[/red]")
                console.print("🔄 [yellow]Please try again...[/yellow]")
            else:
                print(f"\nUnexpected error: {e}")
                print("Please try again...")
            continue
        
        # Ask if user wants to continue (only for research operations)
        if choice in ["1", "2", "3"]:
            if config.use_rich_formatting:
                continue_choice = Confirm.ask("\nWould you like to conduct another research?", default=True)
            else:
                continue_choice = input("\nWould you like to conduct another research? (y/n): ").strip().lower() in ['y', 'yes', '']
            
            if not continue_choice:
                if config.use_rich_formatting:
                    console.print("\n👋 [bold green]Thank you for using the Advanced Research Agent![/bold green]")
                    console.print("[cyan]Happy researching![/cyan] 🔬✨")
                else:
                    print("\nThank you for using the Advanced Research Agent!")
                    print("Happy researching!")
                break

if __name__ == "__main__":
    main()
